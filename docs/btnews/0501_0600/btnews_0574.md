---
title: 【睡前消息574】ChatGPT是做题家 中国欠他一套模拟卷
date: 2023-04-09
---


::: tabs
@tab:active Bilibili
<BiliBili bvid="BV1Tm4y1m7ty" height="500px"/>

@tab YouTube
<YouTube id="hvLXeLwdp5g" height="500px"/>
:::

大家好，2023年4月9日星期日，欢迎收看574期睡前消息，请静静介绍话题。

ChatGPT是今年互联网最热话题之一，从年初开始，就连续有观众想让我们表达对ChatGPT的看法。

03月15日，OpenAI公司发布了GPT-4，可以根据手绘草图，十秒生成网站代码。

![](/images/btnews/0501_0600/0574/2c27a313-8302-44bb-8343-fc4715abd959.png)


摩根士丹利财富管理部门宣布已经使用 GPT-4，帮员工更好地调用公司资料库，现在每天至少 200 名员工在用。

![](/images/btnews/0501_0600/0574/4785d285-4451-4861-850e-065bf20eb5d1.png)

因为担心快速发展的AI技术失控，有一批科技名人发起联名信，呼吁暂停AI研发半年，给人类留一点思考和喘息的机会。

督工你怎么看ChatGPT的发展？会用ChatGPT接替睡前消息工作室的工作吗？

目前不会，尤其静静你可以放心。

咱们工作室注意到ChatGPT是从一月份开始，当时美国大学纷纷发通知，禁止大学生用ChatGPT做作业。但禁止就是最好的广告，一月底的时候，美国在线课程供应商 Study.com 发了个问卷，显示89%的学生会用ChatGPT做作业。到了2月6号，新闻说ChatGPT通过了谷歌的程序员面试，然后就是一连串的新闻说某个公司打算用ChatGPT取代员工，所以大裁员。


![](/images/btnews/0501_0600/0574/36f05dd0-f035-4b1c-9c5b-aafeb6abd82f.png)

大公司的举动，一向影响舆论，但要说ChatGPT能加入商业团队，甚至能到我们的工作室当一个核心员工，我觉得太夸张了。因为ChatGPT通过程序员面试，并不能说明什么问题。等到ChatGPT做出有实际竞争力的复杂产品，再担心工作也不迟。

大企业强调标准化，入职测试往往是有套路的；而一个还在应对激烈竞争的公司，工作往往根本没有套路，所以面试和真实的工作需求经常脱节。具体到程序员的面试，应聘者一般会得到清晰的需求，明确的运行环境，只需要表达短时间做题能力就能入职。而真实的场景是程序员花费大量时间去沟通需求，研究软件环境，搞清楚自己要做什么，不能做什么，最后才是提供一组能解决问题的代码。

![](/images/btnews/0501_0600/0574/834f0e0a-cee7-4ca2-988c-1e0d4d1670a5.png)

所以，能给公司赚钱的程序员，未必就能通过面试。最著名的例子，是 Max Howell 写出了苹果电脑平台上最强的软件包管理工具（homebrew），在谷歌公司内部程序员群体的覆盖率可能有 9 成。但是他本人去谷歌面试的时候，被考官问了一个翻转二叉树问题，要求在白板平台上现场写程序，结果没能通过测试，被赶走了。

和大公司面试题相比，学校作业的要求更明确，背景条件定义更清晰，很容易验证是否做对。所以肯定会有学生企图用 ChatGPT 交作业。

我认为，优秀的员工应该主动发现问题，提出问题，明确定义问题的边界，最后一件小事才是解决问题。很多时候，明确定义问题边界之后，可以发现问题根本解决不了，能把“无法解决”的信息传递给同事的员工才是优秀的员工。

至于限于做题家思维的人，自己提不出问题，坚持要为每个问题找一个答案，甚至求助于ChatGPT编一个四平八稳的答案，这种人对任何组织都是有害的，本来也不是我们工作室需要的人。

静静你现在有两份任务，一个是修订其他同事的文案，让它更符合我们节目的风格。这部分工作，我觉得可以训练ChatGPT帮忙提高效率。但你主要的任务，是对我、对其他同事提出问题，质问稿件里不清晰、不完善的论证。作为一个提问题的人，你不用担心因为ChatGPT这个做题家的竞争而下岗。

![](/images/btnews/0501_0600/0574/7f488677-8bc6-4787-947b-63430781efec.jpg)

我放心了，督工你和工作室的其他同事呢？

我们暂时也不怕。

去年这个时候的[424期](../0401_0500/btnews_0424.md)节目，我介绍过工作室的工作流程。大多数同事的工作，是从各个角度使用搜索引擎和其他基本数据库，围绕时事新闻逐步组织逻辑链条。在确定逻辑可靠性之后，我们搭建的社会模型虽然简陋，但也能暴露很多现实社会的矛盾，让每个观众都能理解以岭药业造谣，独山县借债这一类严重问题。

现在ChatGPT来了，对我们的工作冲击很小。因为我们不是抢时间的一线记者，并不需要以最快的速度提供基本信息。我们需要的是比观众更广阔的信息来源，看到每一个和基本事实相关的平行资料，然后像搭积木一样，从中拼凑各种可能成立的逻辑链。最后，通过查证事实，相互对照，确定最可靠的一条逻辑链。

在信息的广度和附加信息数量方面，ChatGPT和搜索引擎的上限还差得很远。在相互对比，验证可靠性方面，ChatGPT更是不如熟练使用搜索引擎的同事。所以我们必须通过各种搜索引擎进行大量阅读，而不是接受ChatGPT加工过的二手答案。

我用最近的日常工作举一个简单例子：

![](/images/btnews/0501_0600/0574/0a6a01f8-10e0-4eaf-94be-5d9dba9ee0ea.png)

第[567期](./btnews_0567.md)节目介绍了我20多年前读过的书《大预言-未来500年》，书上写着作者是阿德里安-贝里。为了搭建逻辑链，我需要知道这位作者是否去世，是否有最近的作品。

![](/images/btnews/0501_0600/0574/83ba653c-56e6-4621-a8b8-424eb49d7d38.png)

同事先让ChatGPT回答，得到一个信息，阿德里安-贝里先生已经在2016年3月21日去世。这条信息可能是真的，但是追问下去，ChatGPT给不出消息来源，没法验证真实性，我们不能把这样的信息直接塞给观众。把问题换成英文，ChatGPT还是给不出来源。



![](/images/btnews/0501_0600/0574/8b5a6686-a379-4cb9-a632-8ebeaba16d18.png)



把同样的问题塞给newbing，再次得到了另一个答案，但是必须追问两次才能得到一个信息来源，原来是维基百科。



![](/images/btnews/0501_0600/0574/925312af-b332-4ade-ae87-6481fe22242c.png)



放下AI，直接用传统搜索引擎，效率就高多了。直接谷歌搜索书名。



![](/images/btnews/0501_0600/0574/e2abed50-e9d1-4bdd-a233-6cbdeba1726f.png)



中文互联网一无所获，好在谷歌可以提供作者的英文名。再拿着英文名随便一搜，维基百科就给了答案：2016年4月18日去世，还提供了他在互联网上的其他痕迹，基本证实了就是我们要找的人。

众所周知，我只用百度，上面的工作是我让同事做的。ChatGPT需要几十秒来生成回答，而搜索引擎不到一秒返回答案，让AI生成答案的时间，足够我的同事找到确切信息甚至可以做及两次相互对比了。类似的工作，每天在办公室会发生上百次，我们不会把ChatGPT当做主要写作工具的。

现在ChatGPT还能带来惊喜，一个很重要的原因是搜索引擎有使用门槛，大多数人之前并不擅长用搜索引擎工作。如果只看百度第一页，真的会把命送给李彦宏；如果不会反复迭代关键词，只看谷歌前几页，也不能通过搜索拿出有新意的逻辑链。

具体来说，普通人缺乏知识和技能，不知道如何设定关键词，不知道如何利用已经搜索到的浅层内容寻找深层内容，在互联网上只是信息的被动接受者，类似一个坐着听别人说话的盲人。这时候遇到一个乖巧的ChatGPT做互联网导盲犬，在信息获取方面的确有明显的进步。

![](/images/btnews/0501_0600/0574/6217c4d1-521d-4383-ba55-a9d9d73554be.jpg)

ChatGPT也有类似于搜索引擎的使用门槛，但是明显低得多，因为它替人类完成了初选工作，通过合并内容，直接建立逻辑，剥夺了让用户“再筛选”的自由，同时也降低了使用难度，这让很多人会担心ChatGPT制造失业。

现在办公室的同事，都已经翻越了使用搜索引擎的基本门槛，也许会参考ChatGPT做出的信息初选，决不允许ChatGPT限制我们进一步筛选深度信息的能力。所以对于睡前消息团队来说，ChatGPT眼下不是竞争者，只是一个乖巧但能力不强的小助手。

刚才督工你说ChatGPT也有使用门槛，怎样才能让ChatGPT提供更准确的信息？

![](/images/btnews/0501_0600/0574/43e0b14f-e195-4f43-b77c-d8b53362e58c.jpg)

GPT的全称是：生成型预训练翻译器，（Generative Pre-trained Transformer）一个能通过预先积累资料，理解人类自然语言的翻译器。同时它可以直接调用计算机和数据库的硬件，以人类难以想象的速度看资料，参考以往的例题。

所以，用GPT解决定义明确的问题，就像让一个学生拥有无限的资料，无限的时间，参加一场不超过教学大纲的开卷考试，其中大多数问题有标准答案，这个学生得高分甚至得满分是大概率事件。可以说，ChatGPT的最基本设计目标，就是当一个不知疲倦的做题家。如果你想让做题家输出标准答案，那就必须给他高质量的提问。

OpenAI公司发论文介绍过自己的基本训练方式：给出成熟文本的前几个字，让它预测下一个字；然后把这个预测的字拼在后面，成为新的输入，继续预测。这个训练方式很有信息论基本定义的风格。当年香农就是用类似的方式，计算了人类普通文本的信息熵，定义了“信息”的计量方式。

香农认为，信息的本质是消除“不确定性”，空出来的下一个字越是不可预测，提供的信息量就越大。反过来说，如果我们能在前面的内容增加信息量，降低下一个字需要包含的信息量，就越容易预测正确。

所以，问题越清晰，前置的文本越多，限制条件越是量化，AI的回答就越靠谱。这和我们的日常工作有相似之处。

平时人类接手一份复杂工作，首要的任务不是立刻开始计算或者测量，而是要先看资料，积累足够资料之后逼问自己，要做的到底是什么事情，不断细化对自己的需求，最后才是制定具体的操作方案。到了这一步，其实方案完全可以交给助手完成了。ChatGPT就是这样一个助手，一个暂时不会提出问题，只会解答明确问题的“做题家”助手。我们必须学会管理助手。

![](/images/btnews/0501_0600/0574/cb1c1cf4-90c1-45e6-87f9-c459bd7adbbd.png)

如果是人类助手，会学着自我提升。比如刚毕业只会做题的学生，如果足够用心，在当助手执行任务的过程中，会反过来提问题，补充自己完成任务所需要的信息，加深对任务的理解，最终优化自己的工作。多做几次，他就会试着超越助手的身份，主持工作。

但是目前ChatGPT还不会反问要求更多的条件，也不会根据自己已经得到的信息去优化内容，只能算是比较死板的助手，需要更多的管理才能干活。

![](/images/btnews/0501_0600/0574/f1f15631-ccc2-497a-9abf-bc606933a458.jpg)

一个暂时停留在“做题家”水平的助手，为什么会对世界造成这么大的冲击？

因为我们的政府部门和大企业里面积压了很多做题家，而且不是学校考试考出来那种有一点通用性的做题家，只是针对特定问题的畸形做题家。比如说政府里的资深秘书，比如说给某些金融企业筛选项目的经理，比如某些商业企业负责上传下达、评估分店工作的中层干部，又比如说某些老牌媒体里面用一套八股套话应付全世界新闻的社论作者。都是ChatGPT最容易第一时间取代的人。

这个群体拿高工资，占重要的职位，不是因为有创造力，也不是因为能应对复杂工作，而是因为他们运气好，比较早进入成熟的工作流程，占据了一个重要，但已经固化的环节。他们擅长用一些外人看来比较复杂的流程，去应付所有问题。

仅从技术角度说，这些寄生在流程上的职位，早就可以用自动化设备替换了，甚至用几个excel表格就能做得更好。他们一直能混到今天，原因是传统的办公自动化系统有一定的使用门槛；同时这些做题家也和管理层磨合出了一定的默契，降低了沟通成本，所以管理层宁可保守一点雇成熟的人。万一出问题了，也能送一个有身份证号码，有行政级别的人出去背锅挨骂。

![](/images/btnews/0501_0600/0574/31af9b7f-899a-488e-87b2-0eee2d520e27.png)

到了2023年，通用做题家ChatGPT来了，再次降低了办公自动化的门槛。ChatGPT可以吸收一线人员的口头报告，然后根据以往的模板，快速生成文件。有成型规范的地方，ChatGPT学套路比任何人都快；没有成型规范的地方，ChatGPT偶尔能总结出人类还没意识到的套路。所以过去几十年积累的冗余体面职位都感受到了威胁。

更重要的是，ChatGPT用人类语言进行交流，可以通过几次快速合作和人类达成信任，这当然会冲击一大批人的职位。而这些职位往往最闲，知道自己换不了工作，喊救命的声音最大，在局部地区造出了世界末日的效果。

这么说，ChatGPT也只是一个高效办公自动化工具而已，淘汰一批混日子的中产，然后世界一切照旧，是这样吗？

没有那么简单，用一个不知疲倦的做题家，帮助人类解决已知的套路化问题，迫使更高比例的人类从事创造性工作，已经构成产业革命的重要前提了。

![](/images/btnews/0501_0600/0574/783f0f0f-286c-4ebc-9bef-22503817d745.png)

[410期](../0401_0500/btnews_0410.md)节目，我介绍过第一次工业革命的关键节点。瓦特蒸汽机的核心技术之一，就是用一个自动反馈设备替代了操作工，这里回顾一下：

瓦特并没有发明蒸汽机，但是他在能源利用和信息化控制两方面改良了蒸汽机，让蒸汽机从一种专用的采矿辅助设备，变成了各行业通用的工业核心设备。

在能源利用方面，瓦特设计了独立的冷凝器，不需要每个做功循环都消耗气缸的全部热量，明显提高了蒸汽机的效率。但是，装上单独的冷凝器之后，蒸汽机变成了一个正反馈系统——机器转得越快，汽缸就烧得越热，而汽缸烧得更热，又会推动机器转得更快。如果没有人力调节，放出一部分额外的蒸汽，机器很快就会被自身的力量破坏。

为了保护机器，节约人力，必须给蒸汽机增加自动负反馈调节机制，让蒸汽机的转速信息能调节输入的能量。瓦特的解决方案是离心调速器。离心调速器跟着蒸汽机一起转动，随着蒸汽机转速越来越快，调速器上的两个铁球因为离心效应向外运动。铁球向外运动的趋势会推动一个杠杆，逐渐关闭向汽缸输送蒸汽的阀门，减小蒸汽对活塞的推力，降低蒸汽机的转速。最终蒸汽机的转速和铁球的位置会达成相对平衡，让无人看管的蒸汽机稳定输出动力。

离心调速器是激发工业革命的最后一项核心科技，节约的不是人的体力，而是人的思考和判断能力。瓦特研发离心调速器的思考过程后来发展成一个专门的学科，自动控制理论。

回到ChatGPT的话题，它能完成套路化的工作，性质类似于瓦特蒸汽机上的铁球，可以节约控制员。尤其是和语言交流相关的工作，过去必须占用人力，在数据库和自然语言之间做翻译。现在我们可以直接把公共数据库接上ChatGPT，等于获取了无限耐心的客服或者私人教师。

![](/images/btnews/0501_0600/0574/5e740cc5-8639-4d67-9874-67034de801cc.jpg)

更进一步说，某些现实中服务业的工作，比如打扫卫生，处理食品，接送快递，装卸货物，机器早就做得比人类更好了，只是因为机器和人类沟通太麻烦，不能随时调整工作流程，才一直用人来做。ChatGPT实现的自然语言沟通能力，早晚会用到家政机器人身上。

前面用第一次工业革命和瓦特蒸汽机举例子，那个时代离我们有点远。但是20世纪90年代成熟的个人电脑桌面操作系统和鼠标结合，对社会的冲击应该还有很多人记得。

在图形界面和鼠标普及之前，使用计算机要输文字命令，只有经过严格训练，记下复杂命令的人才能快速计算机，甚至可以说，这时候所有的计算机用户都是程序员。有了图形界面以后，普通人就不用学程序，学命令了，只要动动鼠标就能操纵计算机。到了21世纪智能手机时代，动一动拇指就能接入互联网，所以信息化时代很快就冲击到全人类。

现在ChatGPT又提供了一个新的人机交互方式，让人类用自然语言就能使用计算机的大多数功能，而且还能布置比较复杂的任务，这必然会再次颠覆现有的经济秩序。我认为，ChatGPT代表的AI革命，对人类社会的冲击，最低也是30年前IT革命的水平。乐观一点估计，可能最终和200年前的工业革命相当甚至超过，中国社会不能对新技术革命的冲击力掉以轻心。

![](/images/btnews/0501_0600/0574/02785977-6f44-42f7-82d2-8f09c61b913c.gif)

另外，ChatGPT这一类高质量AI服务，几乎必定是在线运行。下载到每个人电脑上的东西只能是一个粗糙的山寨版，这意味着盗版软件时代彻底结束了，每个人、每个企业要跟进新时代，都必须为自己得到的信息服务付钱。美国企业从windows3.0时代培养的全世界盗版使用习惯，现在终于要得到全面回报。技术先进的企业，可以理直气壮地从全世界回收成本，开发下一代产品，继续拉开和竞争者的距离。

所以，就算ChatGPT只在现有水平上不断改良，充分解决人类和机器的自然语言沟通问题，完成人类精确定义的套路化工作，已经不能小看了。2023年的睡前消息编辑部不怕ChatGPT，未来的中国社会不能轻视新产业革命带来的颠覆性变化，否则就要吃大亏。

更值得担心的是，虽然我们知道ChatGPT只是一个语言学模型，没有人类哲学意义上的智力。但是随着训练模型的增长，它的回答准确性有指数增长的趋势，从玩具到实用的秘书助手，ChatGPT只经历了大半年时间。随着资金越来越充足，收费业务越来越广泛，没有人也不知道这波AI技术增长会冲到哪一步。

![](/images/btnews/0501_0600/0574/8755baa5-076e-46b8-b449-87e17f4eecc3.png)

如果有一天，AI忽然表现出超越普通人的创造力。这就不能简单地用生产工具的进步来对比了。一个创造性工作比人类还强的AI系统，地位要高于瓦特的蒸汽机、爱迪生的发电厂，可能只有定居农业的诞生能与之相提并论。人类把定居农业之前的时代称为“史前时代”，把农业社会和工业社会的历史称为“有史以来”，也许将来我们会把AI全面超越人类那一天称为AI元年。这种可能性不一定会变成现实，但绝对不能忽视。

总的来说，这一波AI技术的下限，是给人类提供了不知疲倦的做题家助手，可能会激发一次中型产业革命；上限则不可估量，或许会把人类历史推到无法想象的阶段。无论未来AI技术走到哪一步，中国社会都必须严肃对待，避免像200年前的清朝，50年前的苏联那样被新技术革命踩在脚下。

![](/images/btnews/0501_0600/0574/75e8edbe-5a6d-463c-8d03-13eeb04126d5.jpg)

过去几十年，我们发展经济先是靠人口红利，利用全世界最庞大的一批中学教育人口搭建工业流水线，赚到了产业升级的机会。到了2015年左右，产业升级表现出了效果，我们的舆论已经不太说人口红利，而是改口说工程师红利了。但我们还是必须严肃地问自己，中国到底有多少工程师和技术人员敢说自己有原创能力。

2003年，我刚到设计院工作的时候，总工办有一个外聘的审图老专家，50年代兰州铁道学院毕业的，技术很强，脾气很坏。他看到我们的图纸，经常会轻蔑地一笑，说这图纸也不是不行，只是我不会说你们是工程师，而是把你们当“绘图匠”。这个称呼我一直记到离开技术岗位，还是不好意思说自己是工程师。总觉得自己干的都是助理工程师的工作。

现在ChatGPT再次给中国提出了类似问题——如果AI能完成绝大多数助理任务，要求所有劳动力都只从事创造性的工作，我们到底有多少人能在经济中发挥价值。下一个问题是，中国经济和教育能不能主动转型，适应AI时代的经济。能，AI助手对我们来说就是如虎添翼，否则就是引火烧身。

中国现在是世界第一工业大国，在很多行业已经超越美国了。如果我们也想有自己主导的AI产业，怎样才能先做出自己的GPT？

前面我给ChatGPT做了基本定性，当前阶段就是一个做题家助手。中国人最清楚怎样培养一个做题家。想要自己的AI赶上，ChatGPT，首先要问你的AI做了多少题。

![](/images/btnews/0501_0600/0574/92c3c3c0-e1ba-4805-b8a0-1109c0fbedbe.png)

GPT-3训练用到的数据集，也就是GPT-3刷过的题库可以在网上查到：

首先是抓取的普通网页（common crawl），占题库比例是60%，但因为没有经过严格筛选，所以权重很低，只有0.44，可以理解为教科书上的课后习题。

第二部分是WebText2，高质量网页，比如说reddit论坛引用的站外网页链接，获得有3个点赞就能入选。这部分占题库比例是22%。权重是2.9。可以理解为模拟考卷，教GPT-3像人类那样讨论问题。

再往下看，权重最高的公开网页是维基百科，虽然比例只占3%，但是权重达到3.4。这几乎可以看做历年考试真题。

最后，OpenAI公司还安排了40个数据标注员，人工写模范问题和回答，精调GPT模型，这就相当于辅导老师一对一辅导。

经历了类似于衡水中学生的层层训练，GPT终于呈现出一定水平的做题能力。但和中学生不一样，GPT不会疲劳，不会厌烦，每一秒都在海量刷题。所以，最主要的限制是有多少题可以刷。

![](/images/btnews/0501_0600/0574/743642cb-d176-47f4-ab74-5c1b66c4217d.png)

在GPT-3全部训练数据中，英文比例占92.65%，中文只占0.1%，这可能反映了美国公司的文化倾向。但是看整个互联网数据，英文内容比例是56.1%，中文还是占1.5%。中国的互联网文化衰落，已经到了要消灭中文的地步。就算是一家中国公司要训练自然语言AIT，大部分训练数据也只能来自英文互联网，让中文当二传手。

对于中国这1.5%网页的质量评价，有智商且有良心的中国人都不会乐观。美国有维基，我们有百度百科；美国有reddit，我们有贴吧和只剩下一口气的天涯，而且每年自己把剩下的优秀内容选出来，随机屠杀一半。至于微信公众号上的东西，良莠不齐不说，连搜索生态都是封闭的，其他公司的AI不能随便搜索利用。最后，只剩下知乎还有一点优秀数据，但先是被管理员屏蔽，然后被知乎运营团队自己制造的盐选狗血故事污染，实在不好意思拿给AI去学习。

![](/images/btnews/0501_0600/0574/a5707e0a-72d4-43fc-990e-b10a828ab499.png)

另外，GPT很大的一部分优势在于代码能力，而全世界最大的代码托管软件是微软的GitHub，其次是乌克兰的GitLab，简体中文互联网没有类似的网站。

![](/images/btnews/0501_0600/0574/00eeccd5-f8af-43ab-8246-587682246d59.png)

在题库差了几十倍，质量差了十几倍的条件下，想让中国AI学生的分数赶超美国，我们只能期待中国养了一个AI天才，学习能力超强，能举一反十，以十反百，靠半部教科书打败学霸。但作为一个普通孩子的父亲，我没那么乐观。

所谓AI的学习能力，基本上就是算法和硬件两方面。

这次OpenAI公司一大进步就是采用了新算法，用更低成本预测模型，把大模型训练从碰运气变成了一定程度的定向挖矿。GPT3是两年前的大模型，GPT4也早在半年前就训练完成。而中国大公司此前并未发布过类似的产品，基本上都是在ChatGPT发布以后突然发个声明说自己早有布局。可以说，中国在算法进度上至少落后两年。

至于说硬件，ChatGPT 需要上万块A100 显卡支持运行，去年九月美国刚刚限制了我们进口A100 高算力显卡。而中国社会自己杀掉了本土高性能游戏产业，显卡方面并没有国产替代品，甚至没有可以预期的替代品。

算法和显卡的问题虽然很大，但也可以靠时间和投入来解决，真正绕不过的问题，还是训练数据。对于AI这个急需长身体的青少年来说，普通网页就像粮食，高质量网页是肉、蔬菜和牛奶。如果我们的少年AI连粗粮都吃不饱，过年才能吃一碗肉，过生日才能喝一瓶奶，就算是有世界上最好的训练场，最好的教练，也不可能培养出奥运会冠军。

![](/images/btnews/0501_0600/0574/07b02b4b-32fc-4044-b1f5-c4a8751335a1.jpg)

这里我再强调一遍，十几年前百度还是一个在世界上举足轻重的网站，而现在全部中文内容加起来，也只占互联网内容的1.5%。2023年的互联网简体中文内容不仅和英文内容没法比，就是意大利语、波斯语、葡萄牙语、土耳其语、日语、德语、法语、西班牙语、俄语，也都比中文的互联网信息丰富。

到了2022年以后，就算是越南语，网页数量也已经是中文的1.5倍，按现在的趋势发展下去，很快中国互联网文化就只能找尼泊尔、肯尼亚去表达优越感了。和中国互联网文化相比，中国足球的成绩简直可以当民族英雄。如果AI技术成为下一波经济发展的关键要素，就算翻译软件能解决一部分问题，我们也可能要被迫在中国文化和发展经济之间做二选一的取舍。

3月底，B站有一个上了全站排行榜的视频，标题是《中文互联网的凋零，正在杀死中国人工智能的未来》，和我表达了类似的观点，推荐各位观众看看。

![](/images/btnews/0501_0600/0574/9493049f-ee30-4c52-8c27-7052e3c29e4d.png)

> [中文互联网的凋零，正在杀死中国人工智能的未来【为什么我们搞不出ChatGPT】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Nm4y1z7AT/)


督工你提到了前几天的著名视频：《中文互联网的凋零，正在杀死中国人工智能的未来》。评论区有人表达了不同意见，办公室的同事也有另外的观点。他们认为，和AI未来能获取，能创造的无限信息相比，人类自己的优质文本数据库不值一提。

当年阿法狗AI只用了很短的时间研究人类棋谱，然后就可以和自己下棋提升水平。现在ChatGPT也开始研究自己产生的内容，尝试消除有毒和错误的部分，所以不必过于担忧中文互联网文化的衰落。在未来AI代表的新文化时代，现有的中文和英文内容，也许都不值一提。督工你对这样的观点怎么看？

在整个睡前消息团队，我的计算机水平和英文水平是最差的，所以我不敢随便否定别人的意见。但前面的意见，有一点我很赞同，就是如果通用AI表现出了原创性，人类过去几千年、几十万年积累的东西，很可能不值一提。甚至我们都无法预测AI会做出哪些创造，会怎样反过来改变人类自身。

但越是对未来没有把握，越是应该收集一些资源，避免彻底随波逐流。打个比方，面对科幻小说式的未来，人类现有的经济、文化也许像是一艘小木船，想利用AI洋流的力量去海的另一边。和洋流、风力相比，人类自己的肌肉力量不值一提，但就算我们不能驾驭天气，起码也应该在船上放几根船桨，多储备一些食物，避免到了海的对面，连选择一处顺眼的海滩登陆的资格都没有。

![](/images/btnews/0501_0600/0574/9a14a067-d744-4de6-a871-d1878bb00dac.jpg)

眼下的，中文AI缺乏的不仅是训练数据的数量，还有更严重的质量问题。自然科学方面好一些，虽然论文灌水、造假严重，但起码也有个逻辑自洽的底线，不能在论文里自己否定自己。在社会科学方面，中文互联网信息大多数是毫无信息量的八股文套话，剩下的信息也包含大量的反科学内容、情绪化内容，以及用大量黑话、代词扭曲的片段化讨论。ChatGPT在中国的第一批应用，就是体制内基层生成废话文件，低俗作者生成伪真实故事，以及普通人模仿官八股新闻写段子。

一句话总结，就是在当前的互联网上，和日常生活规则越近的中文内容，和现实的偏差越大。如果让AI在类似的基础上进化，然后要求AI用自己的能力为人类服务，我担心AI恐怕不一定能正确理解中国人的利益和需求。最后完全可能号称“为中国人服务”，做出恐怖的决定。

所以我还是希望，无论如何先改革中国人自己的文化，让人的文化繁荣起来，再去发展AI时代的文化。面对不可测的未来，这是我们能做的最有价值的事情。

![](/images/btnews/0501_0600/0574/e9d89158-379b-40a1-92f8-3e3726c59bed.png)

今天的节目很长，最后用几个简单问题回顾一下今天的内容：

1 ChatGPT是什么？

ChatGPT是一个不知疲倦的做题家。

2 ChatGPT会淘汰谁？

淘汰那些只会做题，不会提问题，不会开展原创工作的人，包括前几次办公自动化就应该淘汰的那些工具人。

3 中国发展AI产业有什么障碍？

硬件缺显卡，软件缺算法，但最缺的还是让AI做题家自主学习的题库，也就是中文信息。

在信息方面，中文网页数量少，高质量的讨论更少。而且现存数据被人为分割，限制在各个企业APP内部，限制在档案馆莫名其妙的保密规定里面，可搜索性很差，不能变成供养强大AI的土壤。

4中国应该怎么解决问题？

自从19世纪洋务运动，中国人就在反复考虑一个问题，能不能只要西方的先进工业技术，同时保留自己的文化内核，搞一个中国特色社会。过去150年，不同的人给出了不同的答案，这里我不想说谁对谁错。但有一个基本原则，各方面肯定都认同——最终选择的文化，必须是一个繁荣的文化。你接受西方文化也好，保留自己的文化也好，总不可能是一个逐步自我消灭的文化，一个网页数量不如越南的文化。

![](/images/btnews/0501_0600/0574/6e35973d-fe84-45ef-a6cf-6ea47c1ffdac.jpg)

到了AI时代，我们又在更深刻的层次上遇到了同一个问题。允许中国人在互联网上发表言论，尤其是允许自由说实话，这不仅仅是社会主义公民应有的基本权利，是文化繁荣的基本条件，更是发展生产力的前提。真实可靠的中文言论，和导弹、芯片、石油、人口一样，是中国经济竞争力的来源，可以直接决定产业革命的效率，影响国家的生死存亡。

到了这个时候，我觉得无论是支持保留中国文化内核的人，还是支持文化革命的人，都应该放下争论，达成一个基本共识，就是必须先让中国互联网文化繁荣起来，让人民好好说话，给中国AI、中国经济乃至中国文化留一条活路。

574期睡前消息到此结束。提醒观众，别忘了去拼多多搜索 82420或者点击评论区链接，享受百亿补贴折扣福利。文字内容随后发在睡前消息编辑部公众号，节目视频同步在微博“睡前视频基地”发布，我们周二再见！